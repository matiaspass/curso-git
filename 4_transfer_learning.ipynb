{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf7b2b4a-9626-4ee4-9a74-fb4aa2d3ab81",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeec1cc-bb62-4523-8085-be5573774d90",
   "metadata": {},
   "source": [
    "Paper original: The influence of pattern similarity and transfer learning upon the training of a base perceptron B2 [Stevo Bozinovski y Ante Fulgosi]\n",
    "\n",
    "Relacionado:\n",
    "https://pdfs.semanticscholar.org/d6b9/d3de85a43f719be3973ce9ca289d89bc5224.pdf?_ga=2.144951024.554554672.1635970300-1836405539.1635970300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89620392-1870-4da8-8e0a-d932bf01122a",
   "metadata": {},
   "source": [
    "### Ideas principales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd7ba3f-764e-4327-ba58-d9669f86a6e5",
   "metadata": {},
   "source": [
    "* Las capas de extracción de características nos puede servir para otras tareas.\n",
    "* Usar un modelo ya entrenado.\n",
    "* Congelar los pesos sinapticos: entrenar la(s) última(s) capa(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703888be-a767-4ba4-8faa-21ee34e40ef2",
   "metadata": {},
   "source": [
    "**¿Cómo se cuántas capas *freezar*?**\n",
    "\n",
    "Hay que hacer la tarea...\n",
    "\n",
    "https://cs.stanford.edu/people/karpathy/deepvideo/deepvideo_cvpr2014.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d62869-53de-4538-a558-ce8ad4317079",
   "metadata": {},
   "source": [
    "### Recapitulando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5703e-f072-4645-b1db-902d1b2c5987",
   "metadata": {},
   "source": [
    "El aprendizaje por transferencia es una técnica de aprendizaje automático en la que un modelo entrenado en una tarea se reorienta en una segunda tarea relacionada.\n",
    "\n",
    "Utilizar esta técnica puede acelerar el entrenamiento y precisión de nuestro modelo, y con menos datos de entrenamiento.\n",
    "\n",
    "**Dato de color:**\n",
    "- En 1976 Stevo Bozinovski y Ante Fulgosi publican paper que estudiaba el aprendizaje por transferencia en el entrenamiento de redes neuronales. \n",
    "- En 1981 se aplicó y demostró el transfer learning en el entrenamiento de una red neuronal en un dataset de imágenes que eran letras de terminales de PC.\n",
    "\n",
    "\n",
    "\n",
    "**A continuación se proveen algunas situaciones y recomendaciones (de lo que funciona en la práctica):**\n",
    "\n",
    "* **Cuando nuestro dataset es pequeño y similar al original (con el que fue entrenada la red A):** entrenar solo la última capa completamente conectada.\n",
    "\n",
    "* **Cuando nuestro dataset es pequeño y diferente al original:** entrenar solo las capas completamente conectadas.\n",
    "\n",
    "* **Si nuestro conjunto de datos es *big* y similar al original:** congelar las primeras capas (características simples) y entrenar el resto de las capas.\n",
    "\n",
    "* **Si nuestro conjunto de datos es *big* y diferente al original:** entrenar el modelo desde cero y reutilizar la arquitectura de red (usando los pesos entrenados como punto inicial)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9d429-f03c-4d44-975f-1686d89608f9",
   "metadata": {},
   "source": [
    "<img src=\"images/transfer_learning.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142fb60-2f96-4c3e-9824-884708f75847",
   "metadata": {},
   "source": [
    "### ¿Qué podemos plantear de las situaciones planteadas previamente?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9539e9f0-124c-4473-a12c-2ceae7c52633",
   "metadata": {},
   "source": [
    "Que el **tamaño de nuestro conjunto de datos** y la **similitud** que tenga **con el dataset original** son las dos claves a considerar antes de aplicar el aprendizaje por transferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832cbfe1-40c1-498e-b0e0-e8e280f7fd98",
   "metadata": {},
   "source": [
    "# Veamos un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d8b9cc-470b-41fd-b6d3-974b24abbfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e3cda7-984b-4d8b-95af-513b647093f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformacions para usar con el modelo resnet18 entrenado con image net\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'my_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x]) for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, \n",
    "                                              shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# por si se quiere usar en colab con GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834eb7a1-b35d-4055-9aa8-90f9becab1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031f2bd-d0d2-423d-89a9-ac7b2f294d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    \n",
    "    # llevado al intervalo [0, 1]\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001) \n",
    "\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# grid\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d7f3b1-308d-45fe-a94f-c06ca57e55e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoca {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # solo se hace update de gradiente si estamos en fase de training\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # nos vamos quedando con el mejor modelo en caso de que empeore en epocas futuras\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print('Mejor accuracy: {:4f}'.format(best_acc))\n",
    "\n",
    "    # retornar mejor modelos\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada493cb-2c51-4c48-a211-f4145eec7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('Prediccion: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ccf25-023b-4b0c-a427-67b86533d49d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## En este caso solo ajustamos la cantidad de clases y entrenamos partiendo de los pesos ajustados previamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3448bbec-4f4d-4c18-b4d1-c90e69dee1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e584c-7180-41d9-ba26-71de22300218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_ft.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350feaf8-475e-4226-9cb7-52dee1148e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model_ft.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a349f3-670f-4b7c-8562-05817ae7c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b457c4d-0a3e-4bd2-a4af-253e09c9d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98eba21-2e89-4442-aad3-3b4efa3efd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# reducir en un factor de 0.1 cada 7 epocas\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7943b879-00d9-477a-bc4d-6da6ae586f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb7a7f-0fa7-471a-a966-9486ed9a6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2995d6a-6449-407a-bf65-97352babada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3318cf19-4480-44b5-b575-fcd1f811b04c",
   "metadata": {},
   "source": [
    "## En este caso solo vamos a entrenar la capa final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b25c0a2-3ce7-4cf6-9a01-61125c53b2e0",
   "metadata": {},
   "source": [
    "Esto llevará mucho menos tiempo que el caso anterior, ya que no es necesario calcular los gradientes para la mayor parte de la red. Sin embargo, es necesario calcular la propagación hacia adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a665570b-e516-4319-9f02-0484cfca572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# reducir en un factor de 0.1 cada 7 epocas\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9980e-ef83-49b9-85c5-63bcbe741c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa83ce0b-54b6-46ad-be88-c81d365dfe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2141c195-b246-4458-bbc3-d213faebd179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
